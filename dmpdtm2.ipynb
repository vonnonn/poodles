{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage, signal, spatial\n",
    "from scipy.ndimage import morphology\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdal\n",
    "\n",
    "def idw(data):\n",
    "    # Find indices of the ground returns, i.e., anything that is not a nan, and create a KD-tree.\n",
    "    # We will search this tree when looking for nearest neighbors to perform the interpolation.\n",
    "    valid = np.argwhere(~np.isnan(data))\n",
    "    tree = spatial.cKDTree(valid)\n",
    "    \n",
    "    # Now find indices of the non-ground returns, as indicated by nan values. We will interpolate\n",
    "    # at these locations.\n",
    "    nans = np.argwhere(np.isnan(data))    \n",
    "    for row in nans:\n",
    "        d, idx = tree.query(row, k=12) #k = number of nearest neighbors\n",
    "        d = np.power(d, -2) #each item in d raised to its reciprocated power (basis of idw) the value \"r\" also defines the smoothness of the interpolation\n",
    "        v = data[valid[idx, 0], valid[idx, 1]] \n",
    "        data[row[0], row[1]] = np.inner(v, d)/np.sum(d) #nans are replaced with the result of (v * d)/sum(d)\n",
    "        \n",
    "    return data\n",
    "\n",
    "def dmpdtm(inputfile):\n",
    "  \n",
    "    #readin in full res .las , subsampled with Poisson, change radius to reach desired resolution\n",
    "    p = pdal.Reader.las(inputfile).pipeline() | pdal.Filter.sample(radius=1).pipeline()\n",
    "    p.execute()\n",
    "\n",
    "    #create a one dimensional array from the \"Classification\" column\n",
    "    cls = p.arrays[0]['Classification']\n",
    "    #set the array to all ones\n",
    "    cls.fill(1)\n",
    "\n",
    "    #convert X,Y, and Z data to a pandas dataframe\n",
    "    df3D = pd.DataFrame(p.arrays[0], columns=['X','Y','Z'])\n",
    "\n",
    "    #define variables (if we keep k = 0, then I'll clean up the code, remove gstar?)\n",
    "    S = 10\n",
    "    k = 0.000\n",
    "    n = 0.1\n",
    "    b = -0.2\n",
    "\n",
    "    hres = 1\n",
    "\n",
    "    #np.ogrid \"open-grid\", creates a way to index the matrix (access pixels/pts) hres is the step\n",
    "    xi = np.ogrid[p.arrays[0]['X'].min():p.arrays[0]['X'].max():hres]\n",
    "    yi = np.ogrid[p.arrays[0]['Y'].min():p.arrays[0]['Y'].max():hres]\n",
    "\n",
    "    #np.digitize allocates points to bins and then bins are grouped in the df\n",
    "    bins = df3D.groupby([np.digitize(p.arrays[0]['X'], xi), np.digitize(p.arrays[0]['Y'], yi)])\n",
    "\n",
    "    zmins = bins.Z.min() #collects the lowest point in each bin\n",
    "    cz = np.empty((yi.size, xi.size)) #create empty 2d array \n",
    "    cz.fill(np.nan) #fill 2d array with nan\n",
    "    for name, val in zmins.iteritems():\n",
    "        cz[name[1]-1, name[0]-1] = val #adding coordinates to lowest points only\n",
    "\n",
    "    cz = idw(cz)\n",
    "\n",
    "    #create an initial diamond(plus shaped) 2,1 and enlarge it 11 times = 23x,23y\n",
    "    struct = ndimage.iterate_structure(ndimage.generate_binary_structure(2, 1), 11).astype(int)\n",
    "    opened = morphology.grey_opening(cz, structure=struct) #dilate cz with above kernel\n",
    "\n",
    "    #create another plus-shaped (2,1) and enlarge it 9 times = 19x,19y\n",
    "    struct = ndimage.iterate_structure(ndimage.generate_binary_structure(2, 1), 9).astype(int)\n",
    "    closed = morphology.grey_closing(opened, structure=struct) #erode opened with above kernel\n",
    "\n",
    "    #removing low outliers: if any pt in cz is >= 1 meter below the surface of closed then it is set to the \n",
    "    #closed surface value\n",
    "    #need to test lower limit >= 0.5\n",
    "    lowx, lowy = np.where((closed - cz) >= 1.0) \n",
    "    cz[lowx, lowy] = closed[lowx, lowy]\n",
    "\n",
    "    stdev = 14\n",
    "    #product of two guassian arrays with the max normalized to 1, size/window = 113\n",
    "    G = np.outer(signal.gaussian(113,stdev), signal.gaussian(113,stdev))\n",
    "    #fast fourier transform convolution, matrix is padded at 2*stdev\n",
    "    low = signal.fftconvolve(np.pad(cz,2*stdev,'edge'), G, mode='same')[2*stdev:-2*stdev,2*stdev:-2*stdev]/1000.\n",
    "\n",
    "    high = cz - low\n",
    "\n",
    "    erosions = []\n",
    "    granulometry = []\n",
    "    erosions.append(morphology.grey_erosion(high, size=3))\n",
    "    for scale in range(1, S):\n",
    "        erosions.append(morphology.grey_erosion(erosions[scale-1], size=3))\n",
    "    for scale in range(1, S+1):\n",
    "        granulometry.append(morphology.grey_dilation(erosions[scale-1], size=2*scale+1))\n",
    "\n",
    "    out = []\n",
    "    for i in range(1, len(granulometry)):\n",
    "        out.append(granulometry[i-1]-granulometry[i])\n",
    "\n",
    "    gprime = np.maximum.reduce(out)\n",
    "    #xs, ys = out[0].shape\n",
    "    #gstar = np.zeros((xs,ys))\n",
    "    #gplus = np.zeros((xs,ys))\n",
    "    #for ii in range(0,xs):\n",
    "    #    for jj in range(0,ys):\n",
    "    #        for kk in range(0,len(out)):\n",
    "    #            if out[kk][ii,jj] < gprime[ii,jj]:\n",
    "    #                gplus[ii,jj] += out[kk][ii,jj]\n",
    "    #            if out[kk][ii,jj] == gprime[ii,jj]:\n",
    "    #               gplus[ii,jj] += out[kk][ii,jj]\n",
    "    #                #gstar[ii,jj] = kk\n",
    "    #                break\n",
    "\n",
    "    #T = k * gstar + n\n",
    "    Sg = gprime < n\n",
    "\n",
    "    F = cz.copy()\n",
    "    F[np.where(Sg==0)] = np.nan\n",
    "\n",
    "    G = idw(F)\n",
    "\n",
    "    struct = ndimage.iterate_structure(ndimage.generate_binary_structure(2, 1), 1).astype(int)\n",
    "    gradDTM = morphology.grey_dilation(G, structure=struct)\n",
    "\n",
    "    xbins = np.digitize(df3D.X, xi)\n",
    "    ybins = np.digitize(df3D.Y, yi)\n",
    "    nonground = np.where(df3D.Z >= gradDTM[ybins-1, xbins-1]+b)\n",
    "    ground = np.where(df3D.Z < gradDTM[ybins-1, xbins-1]+b)\n",
    "\n",
    "    cls[ground] = 2 #set ground points to 2\n",
    "\n",
    "    output = p.arrays[0]\n",
    "    output['Classification'] =cls\n",
    "\n",
    "    pipeline = pdal.Filter.range(limits=\"Classification[2:2]\").pipeline(output)\n",
    "    pipeline.execute()\n",
    "\n",
    "    #default Progressive morphological filter stacked to catch stragglers (havent'tested with alt parameters)\n",
    "    #need to test with alt smrf\n",
    "    pmf_arr = pipeline.arrays[0]\n",
    "    pipeline = pdal.Filter.pmf().pipeline(pmf_arr) | pdal.Filter.range(limits=\"Classification[2:2]\").pipeline()\n",
    "    pipeline.execute()\n",
    "\n",
    "    #writout las file with ground points only \n",
    "    outputfile = inputfile.replace(\".las\",\"_dtm.las\")\n",
    "    final_out = pipeline.arrays[0]\n",
    "    pipeline = pdal.Writer.las(filename= outputfile).pipeline(final_out)\n",
    "    pipeline.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmpdtm(r\"E:\\IG\\Msimbazi_cropped_full_res.las\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2af442ffedf2c59bb363b642f67e1566fff8c791fb96d248ee72510a00d24cb6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
