{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#created by Josh von Nonn\n",
    "#built from source code provided by Brad Chmambers - based off Mungus et al.,2014.\n",
    "\n",
    "\n",
    "### Optimized for removing pesky outliers from Bali dataset (Villa Batu Belig Sidemen)\n",
    "### This level of outlier scrubbing is most likely not necessary for most datasets. There may be an issue that it removes small patches\n",
    "### of ground points as well. -- needs further assessment\n",
    "\n",
    "from scipy import ndimage, signal, spatial\n",
    "from scipy.ndimage import morphology\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdal\n",
    "\n",
    "def idw(data):\n",
    "    # Find indices of the ground returns, i.e., anything that is not a nan, and create a KD-tree.\n",
    "    # We will search this tree when looking for nearest neighbors to perform the interpolation.\n",
    "    valid = np.argwhere(~np.isnan(data))\n",
    "    tree = spatial.cKDTree(valid)\n",
    "    \n",
    "    # Now find indices of the non-ground returns, as indicated by nan values. We will interpolate\n",
    "    # at these locations.\n",
    "    nans = np.argwhere(np.isnan(data))    \n",
    "    for row in nans:\n",
    "        d, idx = tree.query(row, k=12) #k = number of nearest neighbors\n",
    "        d = np.power(d, -2) #each item in d raised to its reciprocated power (basis of idw) the value \"r\" also defines the smoothness of the interpolation\n",
    "        v = data[valid[idx, 0], valid[idx, 1]] \n",
    "        data[row[0], row[1]] = np.inner(v, d)/np.sum(d) #nans are replaced with the result of (v * d)/sum(d)\n",
    "        \n",
    "    return data\n",
    "\n",
    "def dmpdtm(inputfile):\n",
    "  \n",
    "    #readin in full res .las , subsampled with Poisson, change radius to reach desired resolution\n",
    "    p = pdal.Reader.las(inputfile).pipeline() | pdal.Filter.sample(radius=1).pipeline() | pdal.Filter.outlier(mean_k=17,multiplier=0.35).pipeline() | pdal.Filter.range(limits=\"Classification[0:6]\").pipeline()\n",
    "    p.execute()\n",
    "\n",
    "    #create a one dimensional array from the \"Classification\" column\n",
    "    cls = p.arrays[0]['Classification']\n",
    "    #set the array to all ones\n",
    "    cls.fill(1)\n",
    "\n",
    "    #convert X,Y, and Z data to a pandas dataframe\n",
    "    df3D = pd.DataFrame(p.arrays[0], columns=['X','Y','Z'])\n",
    "\n",
    "    #define variables (if we keep k = 0, then I'll clean up the code, remove gstar?)\n",
    "    S = 10\n",
    "    k = 0.000\n",
    "    n = 0.5\n",
    "    b = -0.2\n",
    "\n",
    "    hres = 1\n",
    "\n",
    "    #np.ogrid \"open-grid\", creates a way to index the matrix (access pixels/pts) hres is the step\n",
    "    xi = np.ogrid[p.arrays[0]['X'].min():p.arrays[0]['X'].max():hres]\n",
    "    yi = np.ogrid[p.arrays[0]['Y'].min():p.arrays[0]['Y'].max():hres]\n",
    "\n",
    "    #np.digitize allocates points to bins and then bins are grouped in the df\n",
    "    bins = df3D.groupby([np.digitize(p.arrays[0]['X'], xi), np.digitize(p.arrays[0]['Y'], yi)])\n",
    "\n",
    "    zmins = bins.Z.min() #collects the lowest point in each bin\n",
    "    cz = np.empty((yi.size, xi.size)) \n",
    "    cz.fill(np.nan) \n",
    "    for name, val in zmins.iteritems():\n",
    "        cz[name[1]-1, name[0]-1] = val #adding coordinates to lowest points only\n",
    "\n",
    "    cz = idw(cz)\n",
    "\n",
    "    ### STARTING MORPOLOGICAL GRADIENTS\n",
    "\n",
    "    erosions = []\n",
    "    granulometry = []\n",
    "    erosions.append(morphology.grey_erosion(cz, size=3))\n",
    "    for scale in range(1, S):\n",
    "        erosions.append(morphology.grey_erosion(erosions[scale-1], size=3))\n",
    "    for scale in range(1, S+1):\n",
    "        granulometry.append(morphology.grey_dilation(erosions[scale-1], size=2*scale+1))\n",
    "\n",
    "    out = []\n",
    "    for i in range(1, len(granulometry)):\n",
    "        out.append(granulometry[i-1]-granulometry[i])\n",
    "\n",
    "    gprime = np.maximum.reduce(out)\n",
    "  \n",
    "    Sg = gprime < n\n",
    "\n",
    "    F = cz.copy()\n",
    "    F[np.where(Sg==0)] = np.nan\n",
    "\n",
    "    G = idw(F)\n",
    "\n",
    "    struct = ndimage.iterate_structure(ndimage.generate_binary_structure(2, 1), 1).astype(int)\n",
    "    gradDTM = morphology.grey_dilation(G, structure=struct)\n",
    "\n",
    "    xbins = np.digitize(df3D.X, xi)\n",
    "    ybins = np.digitize(df3D.Y, yi)\n",
    "    nonground = np.where(df3D.Z >= gradDTM[ybins-1, xbins-1]+b)\n",
    "    ground = np.where(df3D.Z < gradDTM[ybins-1, xbins-1]+b)\n",
    "\n",
    "    cls[ground] = 2 #set ground points to 2\n",
    "\n",
    "    output = p.arrays[0]\n",
    "    output['Classification'] =cls\n",
    "\n",
    "    p = pdal.Filter.range(limits=\"Classification[2:2]\").pipeline(output)\n",
    "    p.execute()\n",
    "\n",
    "    #default Progressive morphological filter stacked to catch stragglers (havent'tested with alt parameters)\n",
    "    #need to test with alt smrf --compare computation time\n",
    "    pmf_arr = p.arrays[0]\n",
    "    p = pdal.Filter.outlier().pipeline(pmf_arr) | pdal.Filter.pmf().pipeline() | pdal.Filter.range(limits=\"Classification[2:2]\").pipeline()\n",
    "    p.execute()\n",
    "\n",
    "    #writout las file with ground points only \n",
    "    outputfile = inputfile.replace(\".laz\",\"_dtm.las\")\n",
    "    final_out = p.arrays[0]\n",
    "    p = pdal.Writer.las(filename= outputfile).pipeline(final_out)\n",
    "    p.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmpdtm(r\"E:\\SMather\\Bali_orig.laz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2af442ffedf2c59bb363b642f67e1566fff8c791fb96d248ee72510a00d24cb6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
