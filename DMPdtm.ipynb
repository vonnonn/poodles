{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was created with source code from https://github.com/chambbj/pdal-notebook/blob/master/notebooks/DMP.ipynb, based off [1] D. Mongus, N. Lukac, and B. Zalik, “Ground and building extraction from LiDAR data based on differential morphological profiles and locally fitted surfaces,” ISPRS J. Photogramm. Remote Sens., vol. 93, no. January, pp. 145–156, 2014.\n",
    "\n",
    "Changes in this algorithm: k = 0 (so, removal of gstar matrix), b = -2, manually set hres (relative to density), added PMF at end to clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage, signal, spatial\n",
    "from scipy.ndimage import morphology\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if adding resolution as a parameter:\n",
    "#determine if goal resolution is feasible? (of course this is contingent upon local machine specs and the user's patience)\n",
    "\n",
    "\n",
    "data_in = \"E:/SFSU/UAS/panca_721000_4426500.laz\"\n",
    "\n",
    "#read in in full res .las , subsampled with Poisson, change radius to reach desired density\n",
    "p = pdal.Reader.las(data_in).pipeline() | pdal.Filter.sample(radius=0.5).pipeline()\n",
    "n_points = p.execute()\n",
    "f'Pipeline selected {n_points} points'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a one dimensional array from the \"Classification\" column\n",
    "cls = p.arrays[0]['Classification']\n",
    "#set the array to all ones\n",
    "cls.fill(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert X,Y, and Z data to a pandas dataframe\n",
    "df3D = pd.DataFrame(p.arrays[0], columns=['X','Y','Z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define variables\n",
    "S = 20\n",
    "#k = 0.000\n",
    "n = 0.1\n",
    "b = -0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can't find any documentation on .ptp(), but it must be the x and y length for computing the area\n",
    "density = n_points / (p.arrays[0]['Y'].ptp() * p.arrays[0]['X'].ptp())\n",
    "#hres = 1. / density\n",
    "#the above method for calculating hres is not suggested\n",
    "#for densities around 1pt/m2 try hres = 1, for densities around 15pt/m2 try hres range: 0.25 to 0.5 (more tests to come)\n",
    "hres = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Point cloud density estimated as\", density, \"pts/m^2. Processing at\", hres, \"m resolution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.ogrid \"open-grid\", creates a way to index the matrix (access pixels/pts) hres is the step\n",
    "xi = np.ogrid[p.arrays[0]['X'].min():p.arrays[0]['X'].max():hres]\n",
    "yi = np.ogrid[p.arrays[0]['Y'].min():p.arrays[0]['Y'].max():hres]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.digitize allocates points to bins and then bins are grouped in the df\n",
    "bins = df3D.groupby([np.digitize(p.arrays[0]['X'], xi), np.digitize(p.arrays[0]['Y'], yi)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zmins = bins.Z.min() #collects the lowest point in each bin\n",
    "cz = np.empty((yi.size, xi.size)) #create empty 2d array \n",
    "cz.fill(np.nan) #fill 2d array with nan\n",
    "for name, val in zmins.iteritems():\n",
    "    cz[name[1]-1, name[0]-1] = val #adding coordinates to lowest points only(not sure why -1 is used here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idw(data):\n",
    "    # Find indices of the ground returns, i.e., anything that is not a nan, and create a KD-tree.\n",
    "    # We will search this tree when looking for nearest neighbors to perform the interpolation.\n",
    "    valid = np.argwhere(~np.isnan(data))\n",
    "    tree = spatial.cKDTree(valid)\n",
    "    \n",
    "    # Now find indices of the non-ground returns, as indicated by nan values. We will interpolate\n",
    "    # at these locations.\n",
    "    nans = np.argwhere(np.isnan(data))    \n",
    "    for row in nans:\n",
    "        d, idx = tree.query(row, k=12) #k = number of nearest neighbors\n",
    "        d = np.power(d, -2) #each item in d raised to its reciprocated power (basis of idw) the value \"r\" also defines the smoothness of the interpolation\n",
    "        v = data[valid[idx, 0], valid[idx, 1]] \n",
    "        data[row[0], row[1]] = np.inner(v, d)/np.sum(d) #nans are replaced with the result of (v * d)/sum(d)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cz = idw(cz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an initial diamond 2,1 and enlarge it 11 times = 23x,23y\n",
    "struct = ndimage.iterate_structure(ndimage.generate_binary_structure(2, 1), 11).astype(int)\n",
    "opened = morphology.grey_opening(cz, structure=struct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create another diamond (2,1) and enlarge it 9 times = 19x,19y\n",
    "struct = ndimage.iterate_structure(ndimage.generate_binary_structure(2, 1), 9).astype(int)\n",
    "closed = morphology.grey_closing(opened, structure=struct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing low outliers: if any pt in cz is >= 1 meter below the surface of closed then it is set to the \n",
    "#closed surface value\n",
    "lowx, lowy = np.where((closed - cz) >= 1.0) \n",
    "cz[lowx, lowy] = closed[lowx, lowy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdev = 14\n",
    "#product of two guassian arrays with the max normalized to 1, size/window = 113\n",
    "G = np.outer(signal.gaussian(113,stdev), signal.gaussian(113,stdev))\n",
    "#fast fourier transform convolution, matrix is padded at 2*stdev\n",
    "low = signal.fftconvolve(np.pad(cz,2*stdev,'edge'), G, mode='same')[2*stdev:-2*stdev,2*stdev:-2*stdev]/1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high = cz - low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erosions = []\n",
    "granulometry = []\n",
    "erosions.append(morphology.grey_erosion(high, size=3))\n",
    "for scale in range(1, S):\n",
    "    erosions.append(morphology.grey_erosion(erosions[scale-1], size=3))\n",
    "for scale in range(1, S+1):\n",
    "    granulometry.append(morphology.grey_dilation(erosions[scale-1], size=2*scale+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "for i in range(1, len(granulometry)):\n",
    "    out.append(granulometry[i-1]-granulometry[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gprime = np.maximum.reduce(out)\n",
    "xs, ys = out[0].shape\n",
    "#gstar = np.zeros((xs,ys))\n",
    "gplus = np.zeros((xs,ys))\n",
    "for ii in range(0,xs):\n",
    "    for jj in range(0,ys):\n",
    "        for kk in range(0,len(out)):\n",
    "            if out[kk][ii,jj] < gprime[ii,jj]:\n",
    "                gplus[ii,jj] += out[kk][ii,jj]\n",
    "            if out[kk][ii,jj] == gprime[ii,jj]:\n",
    "                gplus[ii,jj] += out[kk][ii,jj]\n",
    "                #gstar[ii,jj] = kk\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T = k * gstar + n\n",
    "Sg = gprime < n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = cz.copy()\n",
    "F[np.where(Sg==0)] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = idw(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct = ndimage.iterate_structure(ndimage.generate_binary_structure(2, 1), 1).astype(int)\n",
    "gradDTM = morphology.grey_dilation(G, structure=struct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbins = np.digitize(df3D.X, xi)\n",
    "ybins = np.digitize(df3D.Y, yi)\n",
    "#nonground = np.where(df3D.Z >= gradDTM[ybins-1, xbins-1]+b)\n",
    "ground = np.where(df3D.Z < gradDTM[ybins-1, xbins-1]+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls[ground] = 2 #set ground points to 2\n",
    "len(cls[ground]) #number of ground points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = p.arrays[0]\n",
    "output['Classification'] =cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include only ground points\n",
    "pipeline = pdal.Filter.range(limits=\"Classification[2:2]\").pipeline(output)\n",
    "print(pipeline.execute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default Progressive morphological filter stacked to catch stragglers (havent'tested with alt parameters)\n",
    "#need to test with alt smrf\n",
    "pmf_arr = pipeline.arrays[0]\n",
    "pipeline = pdal.Filter.pmf().pipeline(pmf_arr) | pdal.Filter.range(limits=\"Classification[2:2]\").pipeline()\n",
    "print(pipeline.execute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writout las file with ground points only \n",
    "final_out = pipeline.arrays[0]\n",
    "pipeline = pdal.Writer.las(filename=\"ground_only.las\",).pipeline(final_out)\n",
    "print(pipeline.execute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "51637236c88b7f67ec929484c34bf885e2bb3af581387ab562e768ff7801efe9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
